{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ece6ab3-bf6d-437b-a050-807585232f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a Dataframe using 2d list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e9af536-1b82-4ca0-8df3-28f1aaadeac6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f06ffaa1-0e9b-43f0-8388-da88b73eee91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_2d_list = [\n",
    "    [\"Alice\", 30, \"Alice@gmail.com\"],\n",
    "    [\"Bob\", 25, \"Bob@hotmail.com\"],\n",
    "    [\"Charlie\", 35, \"Charlie@gmail.com\"],\n",
    "    [\"Jenie\", 25, \"Jenie@hotmail.com\"]\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data_2d_list, schema=[\"name\", \"age\", \"email\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c08aaa-624f-4435-9511-00d0c1103538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbdd2032-9bb9-4f19-9419-10ca8e7dd95d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a Dataframe using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "133dc115-989e-45e3-9d11-aaae96b792cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_dict = [\n",
    "    {\"name\": \"Alice\", \"age\": 30},\n",
    "    {\"name\": \"Bob\", \"age\": 25},\n",
    "    {\"name\": \"Charlie\", \"age\": 35}\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data_dict)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a3af270-7192-4fce-9090-f44fa8fc636e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a Dataframe using Row\n",
    "\n",
    "**Row** refers to the `pyspark.sql.Row` class, which is a fundamental data structure representing a single row of data within a DataFrame. It is an _immutable_, dynamically typed object containing a set of key-value pairs, where the keys correspond to the column names in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a91a1e4f-d07b-4daf-bacc-cf9c0cbaf8cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "    Row(name=\"Alice\", age=30),\n",
    "    Row(name=\"Bob\", age=25),\n",
    "    Row(name=\"Charlie\", age=35)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89993d7-cdd0-4406-8fe9-1cf0d5ce1ffc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"name\": [\"George\", \"Hannah\", \"Ian\"],\n",
    "    \"age\": [22, 29, 34]\n",
    "}\n",
    "\n",
    "rows = [Row(name=n, age=a) for n, a in zip(data_dict[\"name\"], data_dict[\"age\"])]\n",
    "df_dict = spark.createDataFrame(rows)\n",
    "display(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "106920eb-40c1-4191-90a2-48a627c7ae41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a dataframe with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b271b1-480b-42dc-85e1-d40bedb6a9bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "data = [\n",
    "    Row(name=\"Alice\", age=30),\n",
    "    Row(name=\"Bob\", age=25),\n",
    "    Row(name=\"Charlie\", age=35),\n",
    "    Row(name=\"Jenie\", age=25)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c74795-e2c5-4fa2-ae7e-a761a79a35b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, schema)\n",
    "df.printSchema()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a057827c-0f21-49d2-82bd-a9eae0ea1a31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a dataframe with numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4996a1ba-cc94-4579-9261-8be5f10d13b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [1, \"Alice\"],\n",
    "    [2, \"Bob\"],\n",
    "    [3, \"Charlie\"]\n",
    "])\n",
    "\n",
    "data_list = [(int(row[0]), str(row[1])) for row in data]\n",
    "\n",
    "df = spark.createDataFrame(data_list, schema=[\"id\", \"name\"])\n",
    "\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b45225-7621-43e0-9808-cc6364692505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_data = '''\n",
    "[\n",
    "    {\"name\": \"Alice\", \"age\": 30},\n",
    "    {\"name\": \"Bob\", \"age\": 25},\n",
    "    {\"name\": \"Charlie\", \"age\": 35},\n",
    "    {\"name\": \"Jenie\", \"age\": 25}\n",
    "]\n",
    "'''\n",
    "\n",
    "df_json = spark.read.json(sc.parallelize([json_data]))\n",
    "\n",
    "display(df_json)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SimpleDataframe",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
